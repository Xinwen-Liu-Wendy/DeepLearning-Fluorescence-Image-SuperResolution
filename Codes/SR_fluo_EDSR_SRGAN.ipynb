{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "T7vE-vx9Hqzx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import copy\n",
        "from collections import defaultdict\n",
        "import torch\n",
        "import pandas as pd\n",
        "from skimage import io, transform\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision\n",
        "from torchvision import transforms, utils\n",
        "from torch import nn\n",
        "import albumentations as A\n",
        "from albumentations import (HorizontalFlip, ShiftScaleRotate, Normalize, Resize, Compose, GaussNoise)\n",
        "import cv2\n",
        "from torch.optim import Adam, SGD\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "import random\n",
        "import itertools\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "from torch import optim\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tatFofNS7Yqq"
      },
      "outputs": [],
      "source": [
        "# Install valuation metrics\n",
        "! pip install torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1ODa6GWv4Ml"
      },
      "outputs": [],
      "source": [
        "# Install valuation metrics\n",
        "! pip install lpips"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install model summary \n",
        "! pip install pytorch-model-summary"
      ],
      "metadata": {
        "id": "--w5xi_TycSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDp0SyktWSb4"
      },
      "source": [
        "##Build datasets and dataloaders"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZE9TjQYdPY-D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQzpuT1lVBLU",
        "outputId": "dc050b49-8621-4f6f-a7ee-239f5ac9821a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GA939edgdmh7"
      },
      "outputs": [],
      "source": [
        "# visualize data\n",
        "img1_path = \"/content/drive/My Drive/Colab Notebooks/SR_fluo_data/train/input/nuclei_03.tif\"\n",
        "img = io.imread(img1_path)\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "\n",
        "sr1_path = \"/content/drive/My Drive/Colab Notebooks/SR_fluo_data/train/target/nuclei_03.tif\"\n",
        "sr = io.imread(sr1_path)\n",
        "plt.imshow(sr)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHHCV6_tv7_F"
      },
      "source": [
        "Build dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "bRKRE-yVK9y8"
      },
      "outputs": [],
      "source": [
        "# Transform for data augmentation\n",
        "def get_transforms():\n",
        "            list_transforms = []\n",
        "            list_transforms.extend([A.RandomRotate90(p=0.5),])\n",
        "            list_transforms.extend([A.HorizontalFlip(p=0.5),])\n",
        "            list_transforms.extend([A.VerticalFlip(p=0.5),])\n",
        "            \n",
        "            list_trfms = Compose(list_transforms)\n",
        "            return list_trfms\n",
        "\n",
        "# Data class\n",
        "class Fluo_data(Dataset):\n",
        "        def __init__(self,path,transforms = None):\n",
        "            self.path = path\n",
        "            self.folders = os.listdir(path)\n",
        "            self.transforms = get_transforms()          \n",
        "        \n",
        "        def __len__(self):\n",
        "            image_folder = os.path.join(self.path,'input/')\n",
        "            self.image_folder = sorted(os.listdir(image_folder))\n",
        "            return len(self.image_folder)\n",
        "              \n",
        "        \n",
        "        def __getitem__(self,idx):\n",
        "            # read  images and masks from the training dataset. \n",
        "            # image represents input low-res image.\n",
        "            # mask represents high-resolution image (target) for low-res image.\n",
        "            image_folder = os.path.join(self.path,'input/')\n",
        "            mask_folder = os.path.join(self.path,'target/')\n",
        "            image_path = os.path.join(image_folder,sorted(os.listdir(image_folder))[idx])\n",
        "            mask_path = os.path.join(mask_folder,sorted(os.listdir(mask_folder))[idx])\n",
        "            \n",
        "            img = io.imread(image_path).astype('float32')\n",
        "            size = 256\n",
        "            img = transform.resize(img,(size,size))\n",
        "            img = cv2.normalize(img, None, 0, 1.0, cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
        "            #img_extend = np.dstack((img, img, img))\n",
        "                       \n",
        "            mask = io.imread(mask_path).astype('float32')\n",
        "            mask = transform.resize(mask,(size,size))\n",
        "            mask = cv2.normalize(mask, None, 0, 1.0, cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
        "            #mask_extend = np.dstack((mask, mask, mask))\n",
        "            \n",
        "            augmented = self.transforms(image=img, mask=mask) # data augmentation\n",
        "            img = augmented['image']\n",
        "            \n",
        "            mask = augmented['mask']\n",
        "                \n",
        "            # convert everything into a torch.Tensor\n",
        "            mask = torch.as_tensor(mask, dtype=torch.float32)\n",
        "            img = torch.as_tensor(img, dtype=torch.float32)\n",
        "            img = img.unsqueeze(0)\n",
        "            mask = mask.unsqueeze(0)\n",
        "            \n",
        "            return img, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "0XmAdEA9U2QG"
      },
      "outputs": [],
      "source": [
        "#loading the data\n",
        "data_path=\"/content/drive/My Drive/Colab Notebooks/SR_fluo_data/train\"\n",
        "data = Fluo_data(data_path)\n",
        "test_data_path = \"/content/drive/My Drive/Colab Notebooks/SR_fluo_data/test\"\n",
        "test_data = Fluo_data(test_data_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lki51ETngUKx"
      },
      "outputs": [],
      "source": [
        "# Check length\n",
        "print(len(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqW1Cad8Viyi"
      },
      "outputs": [],
      "source": [
        "# Check getitem\n",
        "image, mask = test_data.__getitem__(0)\n",
        "print(mask.shape)\n",
        "print(torch.max(image))\n",
        "print(torch.max(mask))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5GvCn7BiaHoy"
      },
      "outputs": [],
      "source": [
        "# Some utility functions to show images\n",
        "\n",
        "# Convert torch tensor to image\n",
        "def image_convert(image):\n",
        "    image = image.clone().cpu().numpy()\n",
        "    image = image.transpose((1,2,0))\n",
        "    image = cv2.normalize(image, None, 255, 0, cv2.NORM_MINMAX, cv2.CV_8U)\n",
        "    return image\n",
        "\n",
        "def plot_img(no_):\n",
        "    images = []\n",
        "    masks = []\n",
        "    random_idx = np.random.choice(len(data),no_)\n",
        "    for i in random_idx:      \n",
        "        image, mask = data.__getitem__(i)\n",
        "        images.append(image)\n",
        "        masks.append(mask)\n",
        "    plt.figure(figsize=(15,10))\n",
        "    for idx in range(0,no_):\n",
        "        image = image_convert(images[idx])\n",
        "        plt.subplot(2,no_,idx+1)\n",
        "        plt.title('Low-res image')\n",
        "        plt.imshow(image,cmap='gray', vmin=0, vmax=255)\n",
        "    for idx in range(0,no_):\n",
        "        mask = image_convert(masks[idx])\n",
        "        plt.subplot(2,no_,idx+no_+1)\n",
        "        plt.title('High-res image')\n",
        "        plt.imshow(mask,cmap='gray', vmin=0, vmax=255)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZyMZX0k2a0OR"
      },
      "outputs": [],
      "source": [
        "plot_img(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojSYx2oFwAlf"
      },
      "source": [
        "Build dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "AYTFkhoPXwmj"
      },
      "outputs": [],
      "source": [
        "# Build the dataloaders\n",
        "# split the training and validation dataset to around 0.9 train and 0.1 val\n",
        "trainset, valset = random_split(data, [43, 5])\n",
        "\n",
        "# build train dataloader\n",
        "train_loader = DataLoader(dataset=trainset, batch_size=2, shuffle = True, num_workers = 0)\n",
        "\n",
        "# build validation dataloader\n",
        "val_loader = DataLoader(dataset=valset, batch_size=2, shuffle = False, num_workers = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqqMBrfEXf4x"
      },
      "source": [
        "## Model construction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-uQYipplaWo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d068fa3-9140-44e6-8158-07d44401c2de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "# Check GPU.\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda:0')\n",
        "else:\n",
        "  device = torch.device('cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrUqAfQRwF2N"
      },
      "source": [
        "EDSR Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fK_S2vtNT3Mg"
      },
      "outputs": [],
      "source": [
        "# Build EDSR model. This code is adapted from https://github.com/soapisnotfat/super-resolution.git\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_channels, base_channel, upscale_factor, num_residuals):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.input_conv = nn.Conv2d(num_channels, base_channel, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        resnet_blocks = []\n",
        "        for _ in range(num_residuals):\n",
        "            resnet_blocks.append(ResnetBlock(base_channel, kernel=3, stride=1, padding=1))\n",
        "        self.residual_layers = nn.Sequential(*resnet_blocks)\n",
        "\n",
        "        self.mid_conv = nn.Conv2d(base_channel, base_channel, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        upscale = []\n",
        "        for _ in range(int(math.log2(upscale_factor))):\n",
        "            upscale.append(PixelShuffleBlock(base_channel, base_channel, upscale_factor=2))\n",
        "        self.upscale_layers = nn.Sequential(*upscale)\n",
        "\n",
        "        self.output_conv = nn.Conv2d(base_channel, num_channels, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "    def weight_init(self, mean=0.0, std=0.02):\n",
        "        for m in self._modules:\n",
        "            normal_init(self._modules[m], mean, std)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_conv(x)\n",
        "        residual = x\n",
        "        x = self.residual_layers(x)\n",
        "        x = self.mid_conv(x)\n",
        "        x = torch.add(x, residual)\n",
        "        x = self.upscale_layers(x)\n",
        "        x = self.output_conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def normal_init(m, mean, std):\n",
        "    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
        "        m.weight.data.normal_(mean, std)\n",
        "        if m.bias is not None:\n",
        "            m.bias.data.zero_()\n",
        "\n",
        "\n",
        "class ResnetBlock(nn.Module):\n",
        "    def __init__(self, num_channel, kernel=3, stride=1, padding=1):\n",
        "        super(ResnetBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(num_channel, num_channel, kernel, stride, padding)\n",
        "        self.conv2 = nn.Conv2d(num_channel, num_channel, kernel, stride, padding)\n",
        "        self.bn = nn.BatchNorm2d(num_channel)\n",
        "        self.activation = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        x = self.bn(self.conv1(x))\n",
        "        x = self.activation(x)\n",
        "        x = self.bn(self.conv2(x))\n",
        "        x = torch.add(x, residual)\n",
        "        return x\n",
        "\n",
        "\n",
        "class PixelShuffleBlock(nn.Module):\n",
        "    def __init__(self, in_channel, out_channel, upscale_factor, kernel=3, stride=1, padding=1):\n",
        "        super(PixelShuffleBlock, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channel, out_channel * upscale_factor ** 2, kernel, stride, padding)\n",
        "        self.ps = nn.PixelShuffle(upscale_factor)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ps(self.conv(x))\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRKX5THYUaK9"
      },
      "outputs": [],
      "source": [
        "model_edsr = Net(num_channels=1, upscale_factor=1, base_channel=64, num_residuals=16).to(device)\n",
        "model_edsr.weight_init(mean=0.0, std=0.02)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_model_summary import summary\n",
        "print(summary(model_edsr, torch.zeros((1, 1, 256, 256)), show_input=True))"
      ],
      "metadata": {
        "id": "UOmP78zsyG5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lI7IxdrIIIAf"
      },
      "source": [
        "SRGAN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "BUrMjaT7GOJn"
      },
      "outputs": [],
      "source": [
        "# Build SRGAN model. This code is adapted from https://github.com/soapisnotfat/super-resolution.git\n",
        "def swish(x):\n",
        "    return x * F.sigmoid(x)\n",
        "\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, kernel, out_channels, stride):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=kernel, stride=stride, padding=kernel // 2)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=kernel, stride=stride, padding=kernel // 2)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = swish(self.bn1(self.conv1(x)))\n",
        "        return self.bn2(self.conv2(y)) + x\n",
        "\n",
        "\n",
        "class UpsampleBlock(nn.Module):\n",
        "    # Implements resize-convolution\n",
        "    def __init__(self, in_channels):\n",
        "        super(UpsampleBlock, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, in_channels * 4, kernel_size=3, stride=1, padding=1)\n",
        "        self.shuffler = nn.PixelShuffle(2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return swish(self.shuffler(self.conv(x)))\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, n_residual_blocks, upsample_factor, num_channel=1, base_filter=64):\n",
        "        super(Generator, self).__init__()\n",
        "        self.n_residual_blocks = n_residual_blocks\n",
        "        self.upsample_factor = upsample_factor\n",
        "\n",
        "        self.conv1 = nn.Conv2d(num_channel, base_filter, kernel_size=9, stride=1, padding=4)\n",
        "\n",
        "        for i in range(self.n_residual_blocks):\n",
        "            self.add_module('residual_block' + str(i + 1), ResidualBlock(in_channels=base_filter, out_channels=base_filter, kernel=3, stride=1))\n",
        "\n",
        "        self.conv2 = nn.Conv2d(base_filter, base_filter, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(base_filter)\n",
        "\n",
        "        for i in range(self.upsample_factor // 2):\n",
        "            self.add_module('upsample' + str(i + 1), UpsampleBlock(base_filter))\n",
        "\n",
        "        self.conv3 = nn.Conv2d(base_filter, num_channel, kernel_size=9, stride=1, padding=4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = swish(self.conv1(x))\n",
        "\n",
        "        y = x.clone()\n",
        "        for i in range(self.n_residual_blocks):\n",
        "            y = self.__getattr__('residual_block' + str(i + 1))(y)\n",
        "\n",
        "        x = self.bn2(self.conv2(y)) + x\n",
        "\n",
        "        for i in range(self.upsample_factor // 2):\n",
        "            x = self.__getattr__('upsample' + str(i + 1))(x)\n",
        "\n",
        "        return self.conv3(x)\n",
        "\n",
        "    def weight_init(self, mean=0.0, std=0.02):\n",
        "        for m in self._modules:\n",
        "            normal_init(self._modules[m], mean, std)\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, num_channel=1, base_filter=64):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(num_channel, base_filter, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(base_filter, base_filter, kernel_size=3, stride=2, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(base_filter)\n",
        "        self.conv3 = nn.Conv2d(base_filter, base_filter * 2, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(base_filter * 2)\n",
        "        self.conv4 = nn.Conv2d(base_filter * 2, base_filter * 2, kernel_size=3, stride=2, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(base_filter * 2)\n",
        "        self.conv5 = nn.Conv2d(base_filter * 2, base_filter * 4, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn5 = nn.BatchNorm2d(base_filter * 4)\n",
        "        self.conv6 = nn.Conv2d(base_filter * 4, base_filter * 4, kernel_size=3, stride=2, padding=1)\n",
        "        self.bn6 = nn.BatchNorm2d(base_filter * 4)\n",
        "        self.conv7 = nn.Conv2d(base_filter * 4, base_filter * 8, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn7 = nn.BatchNorm2d(base_filter * 8)\n",
        "        self.conv8 = nn.Conv2d(base_filter * 8, base_filter * 8, kernel_size=3, stride=2, padding=1)\n",
        "        self.bn8 = nn.BatchNorm2d(base_filter * 8)\n",
        "\n",
        "        # Replaced original paper FC layers with FCN\n",
        "        self.conv9 = nn.Conv2d(base_filter * 8, num_channel, kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = swish(self.conv1(x))\n",
        "\n",
        "        x = swish(self.bn2(self.conv2(x)))\n",
        "        x = swish(self.bn3(self.conv3(x)))\n",
        "        x = swish(self.bn4(self.conv4(x)))\n",
        "        x = swish(self.bn5(self.conv5(x)))\n",
        "        x = swish(self.bn6(self.conv6(x)))\n",
        "        x = swish(self.bn7(self.conv7(x)))\n",
        "        x = swish(self.bn8(self.conv8(x)))\n",
        "\n",
        "        x = self.conv9(x)\n",
        "        return torch.sigmoid(F.avg_pool2d(x, x.size()[2:])).view(x.size()[0], -1)\n",
        "\n",
        "    def weight_init(self, mean=0.0, std=0.02):\n",
        "        for m in self._modules:\n",
        "            normal_init(self._modules[m], mean, std)\n",
        "            \n",
        "def normal_init(m, mean, std):\n",
        "    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
        "        m.weight.data.normal_(mean, std)\n",
        "        if m.bias is not None:\n",
        "            m.bias.data.zero_()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaL34ba9XlRr"
      },
      "source": [
        "##Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NdO4WLTTooV"
      },
      "source": [
        "Training of EDSR model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETk9Oph7ngNJ"
      },
      "outputs": [],
      "source": [
        "# Setting up parameters\n",
        "num_epochs = 50\n",
        "learning_rate = 1e-4\n",
        "save_interval = 1\n",
        "scale = 1\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.L1Loss()\n",
        "optimizer = torch.optim.Adam(model_edsr.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-8)\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
        "                                               step_size=10,\n",
        "                                               gamma=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCC-okGg_kC3",
        "outputId": "ac2e25ad-3327-4a38-cfdf-3e5de7a423ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 1, 256, 256])\n"
          ]
        }
      ],
      "source": [
        "output = model_edsr(image.to(device).unsqueeze(0))\n",
        "print(output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lY_pByS0_2U"
      },
      "outputs": [],
      "source": [
        "! mkdir checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H57Mrj6t2OGj"
      },
      "outputs": [],
      "source": [
        "model_outputs = \"checkpoints\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "FSfrCsfW1RQE"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "def train(model, train_loader, val_loader, optimizer, criterion, num_epochs, scheduler):\n",
        "  train_loss = []\n",
        "  val_loss = []\n",
        "  for epoch in range(num_epochs):\n",
        "      running_train_loss = []\n",
        "      running_val_loss = []\n",
        "      model.train()\n",
        "      for i, (inputs, targets) in tqdm(enumerate(train_loader)):\n",
        "          # Move the inputs and targets to the device (CPU or GPU)\n",
        "          inputs = inputs.to(device)\n",
        "          targets = targets.to(device)\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          \n",
        "          # Forward pass\n",
        "          outputs = model(inputs)\n",
        "\n",
        "          # Compute the loss\n",
        "          loss = criterion(outputs, targets)\n",
        "          running_train_loss.append(loss.item())\n",
        "\n",
        "          # Backward pass and optimization\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "      # Use learning scheduler\n",
        "      scheduler.step()\n",
        "\n",
        "      # Test on validation dataset\n",
        "      model.eval()\n",
        "      #with torch.no_grad():\n",
        "      for inputs,targets in val_loader:\n",
        "          inputs = inputs.to(device)\n",
        "          targets = targets.to(device)\n",
        "          outputs = model(inputs)\n",
        "          loss = criterion(outputs,targets)\n",
        "          running_val_loss.append(loss.item())\n",
        "\n",
        "      # Print loss \n",
        "      epoch_train_loss = np.mean(running_train_loss)\n",
        "      print(\"Epoch [{}/{}], Train Loss: {:.4f}, LearningRate: {} \".format(epoch+1, num_epochs, epoch_train_loss, scheduler.get_lr() ))\n",
        "      train_loss.append(epoch_train_loss)\n",
        "\n",
        "      epoch_val_loss = np.mean(running_val_loss)\n",
        "      print(\"Epoch [{}/{}], Val Loss: {:.4f}\".format(epoch+1, num_epochs, epoch_val_loss))\n",
        "      val_loss.append(epoch_val_loss)\n",
        "\n",
        "      # Save the trained model\n",
        "      if (epoch+1) % save_interval == 0:\n",
        "        torch.save(model.state_dict(), model_outputs + \"/edsr_epoch\" + str(epoch) + \".pth\")\n",
        "\n",
        "  return model, train_loss, val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPZgTC8KxIEv"
      },
      "outputs": [],
      "source": [
        "model_edsr, train_loss, val_loss = train(model_edsr, train_loader, val_loader, optimizer, criterion, num_epochs,lr_scheduler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vm2OHFP3DHO0"
      },
      "outputs": [],
      "source": [
        "# Plot training and validation loss\n",
        "plt.figure()\n",
        "plt.plot(np.arange(len(train_loss)), train_loss, label =\"Train\")\n",
        "plt.plot(np.arange(len(train_loss)), val_loss, label = \"Validation\")\n",
        "plt.xlabel(\"Number of epochs\")\n",
        "plt.ylabel(\"L1 loss\")\n",
        "plt.legend(loc = \"upper right\")\n",
        "plt.savefig(\"Training_edsr.pdf\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y27qs3guDo0L"
      },
      "outputs": [],
      "source": [
        "# Load checkpoint\n",
        "checkpoint_best = torch.load('checkpoints/edsr_epoch19.pth')\n",
        "model_edsr.load_state_dict(checkpoint_best)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7B1isfjxTxUY"
      },
      "source": [
        "Training of SRGAN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NDSSea5OKfdV"
      },
      "outputs": [],
      "source": [
        "# This code is modified from \n",
        "from __future__ import print_function\n",
        "from math import log10\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torchvision.models.vgg import vgg19\n",
        "#import progress_bar\n",
        "\n",
        "\n",
        "class SRGANTrainer(object):\n",
        "    def __init__(self, config, training_loader, testing_loader):\n",
        "        super(SRGANTrainer, self).__init__()\n",
        "        self.GPU_IN_USE = torch.cuda.is_available()\n",
        "        self.device = torch.device('cuda' if self.GPU_IN_USE else 'cpu')\n",
        "        self.netG = None\n",
        "        self.netD = None\n",
        "        self.lr = config.lr\n",
        "        self.nEpochs = config.nEpochs\n",
        "        self.epoch_pretrain = 10\n",
        "        self.criterionG = None\n",
        "        self.criterionD = None\n",
        "        self.optimizerG = None\n",
        "        self.optimizerD = None\n",
        "        self.feature_extractor = None\n",
        "        self.schedulerG = None\n",
        "        self.schedulerD = None\n",
        "        self.seed = config.seed\n",
        "        self.upscale_factor = config.upscale_factor\n",
        "        self.num_residuals = 16\n",
        "        self.training_loader = training_loader\n",
        "        self.testing_loader = testing_loader\n",
        "        self.train_loss = []\n",
        "        self.val_loss = []\n",
        "        self.val_psnr = []\n",
        "\n",
        "    def build_model(self):\n",
        "        self.netG = Generator(n_residual_blocks=self.num_residuals, upsample_factor=self.upscale_factor, base_filter=64, num_channel=1).to(self.device)\n",
        "        self.netD = Discriminator(base_filter=64, num_channel=1).to(self.device)\n",
        "        self.feature_extractor = vgg19(pretrained=True)\n",
        "        self.netG.weight_init(mean=0.0, std=0.2)\n",
        "        self.netD.weight_init(mean=0.0, std=0.2)\n",
        "        self.criterionG = nn.MSELoss()\n",
        "        #self.criterionG = nn.L1Loss()\n",
        "        self.criterionD = nn.BCELoss()\n",
        "        torch.manual_seed(self.seed)\n",
        "\n",
        "        if self.GPU_IN_USE:\n",
        "            torch.cuda.manual_seed(self.seed)\n",
        "            self.feature_extractor.cuda()\n",
        "            cudnn.benchmark = True\n",
        "            self.criterionG.cuda()\n",
        "            self.criterionD.cuda()\n",
        "\n",
        "        self.optimizerG = optim.Adam(self.netG.parameters(), lr=self.lr, betas=(0.9, 0.999))\n",
        "        self.optimizerD = optim.SGD(self.netD.parameters(), lr=self.lr / 100, momentum=0.9, nesterov=True)\n",
        "        self.schedulerG = optim.lr_scheduler.MultiStepLR(self.optimizerG, milestones=[10, 20, 30], gamma=0.2)  # lr decay\n",
        "        self.schedulerD = optim.lr_scheduler.MultiStepLR(self.optimizerD, milestones=[10, 20, 30], gamma=0.2)  # lr decay\n",
        "\n",
        "    @staticmethod\n",
        "    def to_data(x):\n",
        "        if torch.cuda.is_available():\n",
        "            x = x.cpu()\n",
        "        return x.data\n",
        "\n",
        "    def save(self, epoch):\n",
        "        g_model_out_path = \"SRGAN_Generator_model_path{}.pth\".format(epoch)\n",
        "        d_model_out_path = \"SRGAN_Discriminator_model_path{}.pth\".format(epoch)\n",
        "        torch.save(self.netG, g_model_out_path)\n",
        "        torch.save(self.netD, d_model_out_path)\n",
        "        print(\"Checkpoint saved to {}\".format(g_model_out_path))\n",
        "        print(\"Checkpoint saved to {}\".format(d_model_out_path))\n",
        "\n",
        "    def pretrain(self):\n",
        "        self.netG.train()\n",
        "        for batch_num, (data, target) in enumerate(self.training_loader):\n",
        "            data, target = data.to(self.device), target.to(self.device)\n",
        "            self.netG.zero_grad()\n",
        "            loss = self.criterionG(self.netG(data), target)\n",
        "            loss.backward()\n",
        "            self.optimizerG.step()\n",
        "\n",
        "    def train(self):\n",
        "        # models setup\n",
        "        self.netG.train()\n",
        "        self.netD.train()\n",
        "        g_train_loss = 0\n",
        "        d_train_loss = 0\n",
        "        for batch_num, (data, target) in enumerate(self.training_loader):\n",
        "            # setup noise\n",
        "            real_label = torch.ones(data.size(0), data.size(1)).to(self.device)\n",
        "            fake_label = torch.zeros(data.size(0), data.size(1)).to(self.device)\n",
        "            data, target = data.to(self.device), target.to(self.device)\n",
        "\n",
        "            # Train Discriminator\n",
        "            self.optimizerD.zero_grad()\n",
        "            d_real = self.netD(target)\n",
        "            d_real_loss = self.criterionD(d_real, real_label)\n",
        "\n",
        "            d_fake = self.netD(self.netG(data))\n",
        "            d_fake_loss = self.criterionD(d_fake, fake_label)\n",
        "            d_total = d_real_loss + d_fake_loss\n",
        "            d_train_loss += d_total.item()\n",
        "            d_total.backward()\n",
        "            self.optimizerD.step()\n",
        "\n",
        "            # Train generator\n",
        "            self.optimizerG.zero_grad()\n",
        "            g_real = self.netG(data)\n",
        "            g_fake = self.netD(g_real)\n",
        "            gan_loss = self.criterionD(g_fake, real_label)\n",
        "            mse_loss = self.criterionG(g_real, target)\n",
        "\n",
        "            g_total = mse_loss + 1e-3 * gan_loss\n",
        "            g_train_loss += g_total.item()\n",
        "            g_total.backward()\n",
        "            self.optimizerG.step()\n",
        "\n",
        "            #progress_bar(batch_num, len(self.training_loader), 'G_Loss: %.4f | D_Loss: %.4f' % (g_train_loss / (batch_num + 1), d_train_loss / (batch_num + 1)))\n",
        "        self.schedulerG.step()\n",
        "        self.schedulerD.step()\n",
        "        self.train_loss.append(g_train_loss / len(self.training_loader))\n",
        "        print(\"Average G_Loss: {:.4f}, Lr_Generator:{}, Lr_discriminator: {}\".format(g_train_loss / len(self.training_loader), \n",
        "                                                                                     self.optimizerG.param_groups[0][\"lr\"],\n",
        "                                                                                     self.optimizerD.param_groups[0][\"lr\"] ))\n",
        "\n",
        "    def test(self):\n",
        "        self.netG.eval()\n",
        "        avg_psnr = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_num, (data, target) in enumerate(self.testing_loader):\n",
        "                data, target = data.to(self.device), target.to(self.device)\n",
        "                prediction = self.netG(data)\n",
        "                mse = self.criterionG(prediction, target)\n",
        "                psnr = 10 * log10(1 / mse.item())\n",
        "                avg_psnr += psnr\n",
        "                #progress_bar(batch_num, len(self.testing_loader), 'PSNR: %.4f' % (avg_psnr / (batch_num + 1)))\n",
        "\n",
        "        self.val_loss.append(np.mean(mse.item()))\n",
        "        self.val_psnr.append(psnr)\n",
        "        print(\"    Average PSNR: {:.4f} dB, val_MSEloss:{}\".format(avg_psnr / len(self.testing_loader), np.mean(mse.item()) ))\n",
        "\n",
        "    def run(self):\n",
        "        self.build_model()\n",
        "        for epoch in range(1, self.epoch_pretrain + 1):\n",
        "            self.pretrain()\n",
        "            print(\"{}/{} pretrained\".format(epoch, self.epoch_pretrain))\n",
        "\n",
        "        for epoch in range(1, self.nEpochs + 1):\n",
        "            print(\"\\n===> Epoch {} starts:\".format(epoch))\n",
        "            self.train()\n",
        "            self.test()\n",
        "            if epoch > 40:\n",
        "              self.save(epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "FkC6Ub2qLqvT"
      },
      "outputs": [],
      "source": [
        "# Training parameters for SRGAN\n",
        "class Config(object):\n",
        "  def __init__(self, lr, nEpochs, seed, upscale_factor):\n",
        "    self.lr = lr\n",
        "    self.nEpochs = nEpochs\n",
        "    self.seed = seed\n",
        "    self.upscale_factor = upscale_factor\n",
        "\n",
        "config = Config(lr = 1e-3, nEpochs=50, seed = 42, upscale_factor =1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XT6my7wBNiam"
      },
      "outputs": [],
      "source": [
        "model_srgan_trainner = SRGANTrainer(config, train_loader, val_loader)\n",
        "model_srgan_trainner.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PSsndvRdBiE"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.plot(np.arange(config.nEpochs), model_srgan_trainner.train_loss, label =\"Train\")\n",
        "plt.plot(np.arange(config.nEpochs), model_srgan_trainner.val_loss, label = \"Validation\")\n",
        "plt.xlabel(\"Number of epochs\")\n",
        "plt.ylabel(\"Train loss\")\n",
        "plt.legend(loc = \"upper right\")\n",
        "#plt.savefig(\"Training_edsr.pdf\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhiGsIxbX1sb"
      },
      "source": [
        "##Performance evaluation on testing dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8atrkfd7jcv"
      },
      "outputs": [],
      "source": [
        "# Import evaluatin metrics\n",
        "from torchmetrics import PeakSignalNoiseRatio\n",
        "from torchmetrics import StructuralSimilarityIndexMeasure\n",
        "import lpips\n",
        "psnr = PeakSignalNoiseRatio().to(device)\n",
        "ssim = StructuralSimilarityIndexMeasure().to(device)\n",
        "loss_fn = lpips.LPIPS(net='alex').to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WrGfZkM3T6ng"
      },
      "outputs": [],
      "source": [
        "# Evaluate model performance on test dataset\n",
        "def test_eval(test_data, model):\n",
        "  l1_loss = []\n",
        "  mse_loss = []\n",
        "  psnr_list = []\n",
        "  ssim_list = []\n",
        "  lpips_list = []\n",
        "  criterion1 = nn.L1Loss()\n",
        "  criterion2 = nn.MSELoss()\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for i in range(len(test_data)):\n",
        "      input, target = test_data.__getitem__(i)\n",
        "      input = input.to(device)\n",
        "      target = target.to(device)\n",
        "      output = model(input.unsqueeze(0))\n",
        "      output_np = output.reshape(output.shape[1],output.shape[2],output.shape[3])\n",
        "      # Write output to image\n",
        "      im = Image.fromarray(image_convert(output_np))\n",
        "      im.save(\"output{}.tiff\".format(i))\n",
        "\n",
        "      # Compute L1 loss\n",
        "      loss = criterion1(output,target.unsqueeze(0))\n",
        "      l1_loss.append(loss.item())\n",
        "\n",
        "      # Compute MSE loss\n",
        "      loss2 = criterion2(output,target.unsqueeze(0))\n",
        "      mse_loss.append(loss2.item())\n",
        "\n",
        "      # Compute PSNR \n",
        "      psnr_value = psnr(output, target.unsqueeze(0))\n",
        "      psnr_value = psnr_value.clone().cpu().detach().numpy()\n",
        "      psnr_list.append(psnr_value)\n",
        "      \n",
        "      # Compute SSIM\n",
        "      ssim_value = ssim(output, target.unsqueeze(0))\n",
        "      ssim_value = ssim_value.clone().cpu().detach().numpy()\n",
        "      ssim_list.append(ssim_value)\n",
        "\n",
        "      d = loss_fn.forward(output,target.unsqueeze(0)).clone().cpu().detach().numpy()\n",
        "      lpips_list.append(d)\n",
        "\n",
        "      # Display the LR image, output image and HR image.\n",
        "      plt.figure(i)\n",
        "      fig, axs = plt.subplots(1, 3, figsize=(15, 10))\n",
        "      #plt.axis('off')\n",
        "      axs[0].imshow(image_convert(input))\n",
        "      axs[0].set_title('LR image')\n",
        "      axs[1].imshow(image_convert(output_np))\n",
        "      axs[1].set_title('Output image')\n",
        "      axs[2].imshow(image_convert(target))\n",
        "      axs[2].set_title('HR image (Ground Truth)')\n",
        "      plt.savefig(\"test_image{}.pdf\".format(i), format = \"pdf\", bbox_inches = \"tight\")\n",
        "      plt.show()\n",
        "  return l1_loss, mse_loss, psnr_list, ssim_list, lpips_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5HsMh8Vv_7S"
      },
      "outputs": [],
      "source": [
        "l1_loss, mse_loss, psnr_list, ssim_list, lpips_list= test_eval(test_data,model_edsr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-q28FzxWq99"
      },
      "outputs": [],
      "source": [
        "l1_loss2, mse_loss2, psnr_list2, ssim_list2, lpips_list2 = test_eval(test_data,model_srgan_trainner.netG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0c2ROlMH4fvT"
      },
      "outputs": [],
      "source": [
        "print(\"psnr of output: {}\".format(np.mean(psnr_list)))\n",
        "print(\"lpips of output: {}\".format(np.mean(lpips_list)))\n",
        "print(\"ssim of output: {}\".format(np.mean(ssim_list)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUephJGA6oaA"
      },
      "outputs": [],
      "source": [
        "print(\"psnr of output: {}\".format(np.mean(psnr_list2)))\n",
        "print(\"lpips of output: {}\".format(np.mean(lpips_list2)))\n",
        "print(\"ssim of output: {}\".format(np.mean(ssim_list2)))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}